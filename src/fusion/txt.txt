## First we need a motion estimation model for a mobile robot or autonomous vehicle
# for 50hz vehicle not faster! and small change in the heading angle (constant heading rate)
theta_1 = thetat_0 + delta_theta_1
x_1 = x_0 + delta_s_1 * cost(theta_0 + delta_theta_1/2)
y_1 = y_0 + delta_s_1 * sin(theta_0 + delta_theta_1 /2)
delta_s = v_x * delta_t
delta_theta = theta_dot * delta_t


this was from a youtube video
I remeber i used this for a mobile robot once in matlab

x1 = x0 + v*cos(theta)*delta_t
y1 = y0 + v*sin(theta)*delta_t
theta = theta_0 + omega*delta_t


more sophistaced kinemtatics can be utilized if you want more accuracy




TODO: Need to use real time library for the time -->but why ?is there a time constrait?! is there a callback thats being called every 10 ms and you have to fill the buffer in this time constraint!? i don't think so!

should i make distinction between ekf2d 3d . should i create a state space class and inject it into motion model !


take a look at this --> https://robotics.stackexchange.com/questions/23179/sensor-fusion-with-extended-kalman-filter-for-roll-and-pitch
this was for fusing accelerometer with the gyroscoe to get the roll and pitch data! --> but doesn't the imu already provide those?! maybe its not using the acceleration and it only integrate the angular velocities!

https://dsp.stackexchange.com/questions/8860/kalman-filter-for-position-and-velocity-introducing-speed-estimates
https://towardsdatascience.com/kalman-filter-an-algorithm-for-making-sense-from-the-insights-of-various-sensors-fused-together-ddf67597f35e

-------------
motion model for constant heading rate (v and w are constants)
x_dot = v*cos(yaw) = f1
y_dot = v*sin(yaw) = f2
yaw_dot = w = f3


in continuous mode  with the state space like this : [x;y;yaw;v;w]
A = [df1/dx , df1/dy , df1/dYaw , df1/dv , df1/dw
    df2/dx , df2/dy , df2/dYaw , df2/dv , df2/dw
    df3/dx , df3/dy , df3/dYaw , df3/dv , df3/dw
    df4/dx ....
    df5/dx ....] //albate f4 va f5 nadarim dar vaghe v=v va w=w mishe f4 va f5

= [0 0 -v*sin(yaw) cos(yaw) 0
   .  . .. . . . .. . . 
   . .. . . . .. . . . .
   ................
   ................. ]



in discrete mode:
x(k+1) = x(k) + v*cos(yaw(k))*dt =f1
y(k+1) = y(k) + v*sin(yaw(k))*dt = f2
yaw(k+1) = yaw(k) + w*dt  =f3
v(k+1) = v(k) =f4 --> because of my choosen state space in kf i have to write this also
w(k+1) = w(k) =f5 ---> same as above line

A = [df1/dx(k) , df1/dy(k) , df1/dYaw(k) , df1/dv(k) , df1/dw(k)
df2/dx(k) , df2/dy(k) , df2/dYaw(k) , df2/dv(k) , df2/dw(k)
df3/dx(k) , df3/dy(k) , df3/dYaw(k) , df3/dv(k) , df3/dw(k)
df4/dx(k) , df4/dy(k) , df4/dYaw(k) , df4/dv(k) , df4/dw(k)
df5/dx(k) , df5/dy(k) , df5/dYaw(k) , df5/dv(k) , df5/dw(k)
]

so the A would be :

A= [ 1 0 -v*sin(yaw(k))*dt   cos(yaw(k))*dt  0
     0 1  v*cos(yaw(k))*dt   sin(yaw(k))*dt  0
     0 0        1                 0          dt
     0 0        0                 1          0
     0 0        0                 0          1]

state space :
X = [x 
     y
     yaw 
     v 
     w]

TODO: have solid reasons for all your TODOs
TODO: put these in the motion model of constant heading rate not those formula! but right now im gonna convert them in the ekf predict function
TODO: i also didn't implement measurement model yet!
TODO: use observer design so that as soon as cmd_vel or any other velocity source  has changed it would notify the motion model
TODO: P0 zero should me inf if you don't know where the robot is at first iteration. for now I assume we know the first location because im working on tracking not localization
TODO: create a factory for ekf and stuff
TODO: should i make the fusion template not the ekf or what?
TODO(DONE): normalize yaw angle in constion heading rate
TODO: create state space class and not just create a matrix in the ekf!
TODO: when do i know the measurment has arrived and that I should do a ekk update! for now i just go with it assuming I have the Imu measurements
TODO: You need to update the motion models states based on the output of the ekf's update and set velocity based on cmd is wrong now that you updated the states
TODO: EIgen auto differentation for jacobain in motion model --> use the hard code for the firstt 3by3 mat and for other based on the states make the diffs
TODO: take care of Q matrix . it shouldn't keep goind up if we are not moving I guess!
TODO: propgate equation in motion model needs reconsideration. mainly motion model velocity commands may get updated by the output of the ekf if its being updated by or Not. mind the jacobian. changing the equation messes up the jacobian
TODO: https://automaticaddison.com/sensor-fusion-using-the-robot-localization-package-ros-2/ ---> test it with your pkg and robot_locaziation ros pkg
TODO: check the config file of ekf.yaml and get ideas --> another thing:https://github.com/cra-ros-pkg/robot_localization/issues/249 , another thing: have the full states specified but in the matricies put zero (i guess H)
TODO: make it so that the update of ekf happens if the meas data is available
TODO: the observation sources shouldn't be in the ekf templates! it should be optional so if we have an observation it'd correct the states else we only have predcition step
TODO: changed the api of ekf and added setMotionModel instead of gettting it in the constructor
TODO: created the filter node to get the parameters of the sensor topics and states. so create a class memebr var to utilize them. aslo finish the fusion factory and also figure out a elognat way to communicate the sensors data without the template thing
TODO: enqueu the observations
TODO: make the H matrix like a num_states*num_states matrix then make some of the diags 1 based on the sensors state and then createa full states observation and make the one that you don't zero --> this way the states that is not being observed won't get updated
TODO: each specific measurement maybe should have its own H matrix instead of creating a constant H matrix and just make it zero and one based on what state the sensor provides Or not!
TODO: inverse of a matrix with zero on its diagonal would be nan i used a work around and defined R to be fully diag but thats not correct. find a way to just find an inverse of a sub matrix using eigen
TODO: also now you don't have cmd_vel subscriber! add it or go with the odom --> you can use use_control config file to subscribe to cmd_vel and then use the mediator to communicate!
TODO: bad thing about map is you might accidentally add to it! like for example in the getState of ekf so the best thing to do is either do not depend on map size or make the getstateorder func in state space a copy not a reference!
TODO: take care of adding or removing a state from the config file right now i removed x_ddot!
Ekf is template base so the test_ekf.cpp would give me errors on creating ekf because ekf.hpp is not visiible ---> Template classes need to have their implementation visible during compilation
solution --> 
Option 1: Move Entire Template Implementation to Header
Option 2: Explicitly Instantiate Templates at the cpp file -->template class Ekf<geometry_msgs::msg::Twist, sensor_msgs::msg::Imu>;
Option 3: Include ekf.cpp in Test File -->not common practice




for Eigen jacobian --> https://joelcfd.com/automatic-differentiation/
or https://autodiff.github.io/tutorials/


Note: one thing to note is that the jacobian at the prediction step is calculated using the previous states! so if you are updating them then using the hardcoded jacobian matrix you are doing it wrong! so better approach is to use the 
      jacobian function in autodiff which calcs the jacobian using the current state and at the same time propagate the state one time interval forward

autodiff probelm with member class functions for jacobian--> https://github.com/autodiff/autodiff/issues/51
important thing about the jacobian is when you update the states after the jacobian functino you have to do it one by one and USE val() function or else it gives wrong jacobina calculations!

https://answers.ros.org/question/370980/3d-pose-with-imu-and-odometry-using-robot-localization/




gdb : 
https://juraph.com/miscellaneous/ros2_and_gdb/




for debuging run this in the terminal:
first build the project : colcon build --cmake-args -DCMAKE_BUILD_TYPE=Debug
ros2 run --prefix  'gdbserver localhost:3000'  fusion fusion --ros-args --params-file src/fusion/params/ekf.yaml
and then go the main.cpp and hit play button


or for a direct gdb:
ros2 run --prefix 'gdb -ex run --args' fusion fusion --ros-args --params-file src/fusion/params/ekf.yaml   
