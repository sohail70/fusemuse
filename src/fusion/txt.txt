## First we need a motion estimation model for a mobile robot or autonomous vehicle
# for 50hz vehicle not faster! and small change in the heading angle (constant heading rate)
theta_1 = thetat_0 + delta_theta_1
x_1 = x_0 + delta_s_1 * cost(theta_0 + delta_theta_1/2)
y_1 = y_0 + delta_s_1 * sin(theta_0 + delta_theta_1 /2)
delta_s = v_x * delta_t
delta_theta = theta_dot * delta_t


this was from a youtube video
I remeber i used this for a mobile robot once in matlab

x1 = x0 + v*cos(theta)*delta_t
y1 = y0 + v*sin(theta)*delta_t
theta = theta_0 + omega*delta_t


more sophistaced kinemtatics can be utilized if you want more accuracy




TODO: Need to use real time library for the time -->but why ?is there a time constrait?! is there a callback thats being called every 10 ms and you have to fill the buffer in this time constraint!? i don't think so!

should i make distinction between ekf2d 3d . should i create a state space class and inject it into motion model !


take a look at this --> https://robotics.stackexchange.com/questions/23179/sensor-fusion-with-extended-kalman-filter-for-roll-and-pitch
this was for fusing accelerometer with the gyroscoe to get the roll and pitch data! --> but doesn't the imu already provide those?! maybe its not using the acceleration and it only integrate the angular velocities!

https://dsp.stackexchange.com/questions/8860/kalman-filter-for-position-and-velocity-introducing-speed-estimates
https://towardsdatascience.com/kalman-filter-an-algorithm-for-making-sense-from-the-insights-of-various-sensors-fused-together-ddf67597f35e

-------------
motion model for constant heading rate (v and w are constants)
x_dot = v*cos(yaw) = f1
y_dot = v*sin(yaw) = f2
yaw_dot = w = f3


in continuous mode  with the state space like this : [x;y;yaw;v;w]
A = [df1/dx , df1/dy , df1/dYaw , df1/dv , df1/dw
    df2/dx , df2/dy , df2/dYaw , df2/dv , df2/dw
    df3/dx , df3/dy , df3/dYaw , df3/dv , df3/dw
    df4/dx ....
    df5/dx ....] //albate f4 va f5 nadarim dar vaghe v=v va w=w mishe f4 va f5

= [0 0 -v*sin(yaw) cos(yaw) 0
   .  . .. . . . .. . . 
   . .. . . . .. . . . .
   ................
   ................. ]



in discrete mode:
x(k+1) = x(k) + v*cos(yaw(k))*dt =f1
y(k+1) = y(k) + v*sin(yaw(k))*dt = f2
yaw(k+1) = yaw(k) + w*dt  =f3
v(k+1) = v(k) =f4 --> because of my choosen state space in kf i have to write this also
w(k+1) = w(k) =f5 ---> same as above line

A = [df1/dx(k) , df1/dy(k) , df1/dYaw(k) , df1/dv(k) , df1/dw(k)
df2/dx(k) , df2/dy(k) , df2/dYaw(k) , df2/dv(k) , df2/dw(k)
df3/dx(k) , df3/dy(k) , df3/dYaw(k) , df3/dv(k) , df3/dw(k)
df4/dx(k) , df4/dy(k) , df4/dYaw(k) , df4/dv(k) , df4/dw(k)
df5/dx(k) , df5/dy(k) , df5/dYaw(k) , df5/dv(k) , df5/dw(k)
]

so the A would be :

A= [ 1 0 -v*sin(yaw(k))*dt   cos(yaw(k))*dt  0
     0 1  v*cos(yaw(k))*dt   sin(yaw(k))*dt  0
     0 0        1                 0          dt
     0 0        0                 1          0
     0 0        0                 0          1]

state space :
X = [x 
     y
     yaw 
     v 
     w]

TODO: have solid reasons for all your TODOs
TODO: put these in the motion model of constant heading rate not those formula! but right now im gonna convert them in the ekf predict function
TODO: i also didn't implement measurement model yet!
TODO: use observer design so that as soon as cmd_vel or any other velocity source  has changed it would notify the motion model
TODO: P0 zero should me inf if you don't know where the robot is at first iteration. for now I assume we know the first location because im working on tracking not localization
TODO: create a factory for ekf and stuff
TODO: should i make the fusion template not the ekf or what?
TODO: normalize yaw angle in constion heading rate
TODO: create state space class and not just create a matrix in the ekf!
TODO: when do i know the measurment has arrived and that I should do a ekk update! for now i just go with it assuming I have the Imu measurements
TODO: You need to update the motion models states based on the output of the ekf's update and set velocity based on cmd is wrong now that you updated the states
TODO: EIgen auto differentation for jacobain in motion model --> use the hard code for the firstt 3by3 mat and for other based on the states make the diffs
TODO: take care of Q matrix . it shouldn't keep goind up if we are not moving I guess!
TODO: propgate equation in motion model needs reconsideration. mainly motion model velocity commands may get updated by the output of the ekf if its being updated by or Not. mind the jacobian. changing the equation messes up the jacobian
TODO: https://automaticaddison.com/sensor-fusion-using-the-robot-localization-package-ros-2/ ---> test it with your pkg and robot_locaziation ros pkg
TODO: check the config file of ekf.yaml and get ideas --> another thing:https://github.com/cra-ros-pkg/robot_localization/issues/249 , another thing: have the full states specified but in the matricies put zero (i guess H)
TODO: make it so that the update of ekf happens if the meas data is available
TODO: the observation sources shouldn't be in the ekf templates! it should be optional so if we have an observation it'd correct the states else we only have predcition step
TODO: changed the api of ekf and added setMotionModel instead of gettting it in the constructor
TODO: created the filter node to get the parameters of the sensor topics and states. so create a class memebr var to utilize them. aslo finish the fusion factory and also figure out a elognat way to communicate the sensors data without the template thing
TODO: enqueu the observations
TODO: make the H matrix like a num_states*num_states matrix then make some of the diags 1 based on the sensors state and then createa full states observation and make the one that you don't zero --> this way the states that is not being observed won't get updated
TODO: each specific measurement maybe should have its own H matrix instead of creating a constant H matrix and just make it zero and one based on what state the sensor provides Or not!
TODO: inverse of a matrix with zero on its diagonal would be nan i used a work around and defined R to be fully diag but thats not correct. find a way to just find an inverse of a sub matrix using eigen
TODO: also now you don't have cmd_vel subscriber! add it or go with the odom --> you can use use_control config file to subscribe to cmd_vel and then use the mediator to communicate!
TODO: bad thing about map is you might accidentally add to it! like for example in the getState of ekf so the best thing to do is either do not depend on map size or make the getstateorder func in state space a copy not a reference!
TODO: take care of adding or removing a state from the config file right now i removed x_ddot!
      Ekf is template base so the test_ekf.cpp would give me errors on creating ekf because ekf.hpp is not visiible ---> Template classes need to have their implementation visible during compilation
TODO: using the constant acc for velocity estimation and using imu is yeilding bad result due to not being able to stop the robot after giving stop command because acc is 0 when the robot is mvoing with constant vel and in rest so distingusing between the two is important 
      maybe i can use the cmd_vel topic just
TODO: maybe i should make some codes in the callbacks async. maybe use a timer for them
TODO: implement logger()
TODO: maybe visulization should be on another thread (in the timer of the filter node!)
TODO: take care of Q and R and also add intial position for the states
TODO: error handling!
TODO: how to get rid of too many data in the queue? should i delete the old data faster thank the current rate because its highly depandant on the filters rate!
TODO: implement the odom topic. relying only on imu is not gonna work
TODO: Its unstable
TODO: fix the delay using https://answers.ros.org/question/221036/robot_localization-lag/ --> weridly enough if you show odometry in rviz its fast in use sim time false mode but the tf seems to be ahead of time!
TODO: gazebo clock speed which is 10 gonna hurt your simulation --> https://answers.ros.org/question/391570/robot-localization-ekf-capped-at-10hz/  AND https://github.com/cra-ros-pkg/robot_localization/pull/615
TODO: I tested it with a bag file test1 and test2 in rl pkg and it works ok so lets not waste anymore time on the lag issue. but another way to be sure is to use it in an slam pkg like cartogrpher as an odometry source instead of the real odom plugin and rotate in place to see if there is any lag or something
TODO: I can get the jacobian. create a way for people to create their own motion model and you take the jacobian yourself based on what they wrote
TODO: i think a(k+1) = a(k) is not correct is it because it means constant acceleration which clearly is so may be increase the Q on this element so that it trust the measurement 
TODO: whats the point of the prediction if its in the observation not empty if condition. i want it in case the measurement are having trouble getting to the filter. but at the same time i don't want the P cov to explode! so when P is huge the estimation is unreliable so may be i can add sensor_time out like for 10 seconds and that the limit it can do without having measurment. this is 
      double edged sword because the model is gonna predict based on the last measurement information
TODO: get rid of eigen and use only autodiff lib. is it possible?

TODO: you used amet_target export depednenices checkl if the simple model cmake can se this. so remove eigen3 and autodiff see what happens
TODO: initial possition and Q and initial covairance of P set it in the param. put covariance for the odom_filetered topic

solution --> 
Option 1: Move Entire Template Implementation to Header
Option 2: Explicitly Instantiate Templates at the cpp file -->template class Ekf<geometry_msgs::msg::Twist, sensor_msgs::msg::Imu>;
Option 3: Include ekf.cpp in Test File -->not common practice




for Eigen jacobian --> https://joelcfd.com/automatic-differentiation/
or https://autodiff.github.io/tutorials/


Note: one thing to note is that the jacobian at the prediction step is calculated using the previous states! so if you are updating them then using the hardcoded jacobian matrix you are doing it wrong! so better approach is to use the 
      jacobian function in autodiff which calcs the jacobian using the current state and at the same time propagate the state one time interval forward

autodiff probelm with member class functions for jacobian--> https://github.com/autodiff/autodiff/issues/51
important thing about the jacobian is when you update the states after the jacobian functino you have to do it one by one and USE val() function or else it gives wrong jacobina calculations!

https://answers.ros.org/question/370980/3d-pose-with-imu-and-odometry-using-robot-localization/




gdb : 
https://juraph.com/miscellaneous/ros2_and_gdb/




for debuging run this in the terminal:
first build the project : colcon build --cmake-args -DCMAKE_BUILD_TYPE=Debug
ros2 run --prefix  'gdbserver localhost:3000'  fusion fusion --ros-args --params-file src/fusion/params/ekf.yaml
and then go the main.cpp and hit play button


or for a direct gdb:
ros2 run --prefix 'gdb -ex run --args' fusion fusion --ros-args --params-file src/fusion/params/ekf.yaml   

-----------
make the unordered map const and here is a conversation between me and chatgpt:
"
why index.at("x_dot") works but index["x_dot"] doens't???
mind you the index is const unordered map
ChatGPT
Ah, I see where the confusion lies. The difference between index.at("x_dot") and index["x_dot"] in a const unordered map lies in how they handle non-existing keys.

index.at("x_dot"): This method is safe and will throw an std::out_of_range exception if the key doesn't exist in the map. This is good for explicitly handling cases where the key might not be present.

index["x_dot"]: This method is not available in a const-qualified context of the unordered map. In a const map, operator[] is disabled for inserting or modifying elements because it can potentially create a new element if the key doesn't exist, which isn't allowed in a const-qualified context.
"

kholase inke vaghti const ref bargardoni az getStateOrder bayad az index.at use kuni chun in safe hast ke age nabood chizi ijad nakune! --> compiler's intelligence leaves at awe sometimes!


good info on only imu --> https://answers.ros.org/question/232794/can-i-use-robot_localization-package-with-only-imu-data-if-i-couldhow-to-config-the-package/
so if you wanna use only imu you should add bias error as state!

info regarding lidar localization ==> also really good debuging approach is in there
https://github.com/cra-ros-pkg/robot_localization/issues/370


regarding stability of ekf:
https://answers.ros.org/question/373453/robot_localization-imu-yaw-velocity-causes-vertical-drift/


simple overview of rl pkg :
https://answers.ros.org/question/372501/robot-localization-time-stamps/
https://answers.ros.org/question/220538/robot_localization-time-issues/

rl publish rate:
https://github.com/cra-ros-pkg/robot_localization/issues?q=publish+rate











A problem whith the pi to pi angles: see the growth in yaw_dot estimation! when you don't provide a measurement for it!

[INFO] [1704634016.409077827] [Filter]: dt: 0.036641
[INFO] [1704634016.409321155] [Filter]: YAW IN ODOM -3.125029
[INFO] [1704634016.425103141] [Filter]: YAW IN ODOM -3.134004
real ---: 
-0.000172503
  0.00109223
    -3.12503
 8.47553e-05
           0
           0
X_BEFORE: 
-0.000169652
  0.00109262
    -3.11392
 8.82816e-05
    0.134111
 0.000127683
X: 
-0.000172503
  0.00109223
    -3.12503
 8.47553e-05
    0.124609
 0.000124668
[INFO] [1704634016.428546729] [Filter]: dt: 0.016147
real ---: 
-0.000173055
  0.00109224
      -3.134
 7.23185e-05
           0
           0
X_BEFORE: 
-0.000172507
  0.00109223
    -3.12502
 8.47615e-05
    0.124609
 0.000124668
X: 
-0.000173055
  0.00109224
      -3.134
 7.23185e-05
    0.124585
 0.000124634
[INFO] [1704634016.431601605] [Filter]: dt: 0.000050
[INFO] [1704634016.445043500] [Filter]: YAW IN ODOM 3.139337
real ---: 
-0.000177266
  0.00109172
     3.13934
 8.42112e-05
           0
           0
X_BEFORE: 
-0.000174037
  0.00109223
    -3.13231
  7.4011e-05
    0.124585
 0.000124634
X: 
-0.000177266
  0.00109172
     3.13933
 8.42112e-05
       4.758
  0.00013217
[INFO] [1704634016.448035602] [Filter]: dt: 0.013580
[INFO] [1704634016.465048648] [Filter]: No obs is in queue 0
[INFO] [1704634016.465197424] [Filter]: YAW IN ODOM 3.128595
[INFO] [1704634016.485049814] [Filter]: YAW IN ODOM 3.117826
real ---: 
-0.00018182
 0.00109122
     3.1286
7.94497e-05
          0
          0
X_BEFORE: 
-0.00018039
 0.00109173
   -2.96734
8.91145e-05
      4.758
 0.00013217
X: 
-0.00018182
 0.00109122
    3.12859
7.94497e-05
    16.3999
0.000113712
[INFO] [1704634016.487715055] [Filter]: dt: 0.037099
real ---: 
-0.000182421
  0.00109125
     3.11783
 7.48636e-05
           0
           0
X_BEFORE: 
-0.000181823
  0.00109122
     3.12924
 7.94542e-05
     16.3999
 0.000113712
X: 
-0.000182421
  0.00109125
     3.11783
 7.48636e-05
     16.3999
 0.000113703
[INFO] [1704634016.490854345] [Filter]: dt: 0.000040
[INFO] [1704634016.505084545] [Filter]: YAW IN ODOM 3.106167
real ---: 
-0.000179651
  0.00109108
     3.10617
 -0.00012973
           0
           0
X_BEFORE: 
-0.000183496
  0.00109128
    -2.92991
  7.6496e-05
     16.3999
 0.000113703
X: 
-0.000179651
  0.00109108
     3.10616
 -0.00012973
     20.9837
 -4.2906e-05
[INFO] [1704634016.509568141] [Filter]: dt: 0.014357
[INFO] [1704634016.525053221] [Filter]: YAW IN ODOM 3.093628
real ---: 
-0.00018436
 0.00109048
    3.09363
 8.9316e-05
          0
          0
X_BEFORE: 
-0.000177633
  0.00109101
    -2.85032
-0.000130398
     20.9837
 -4.2906e-05
X: 
-0.00018436
 0.00109048
    3.09362
8.93159e-05
    25.9071
0.000139085




ros2 pkg create --build-type ament_cmake model --dependencies autodiff Eigen3 fusion pluginlib --library-name model
https://docs.ros.org/en/galactic/Tutorials/Beginner-Client-Libraries/Pluginlib.html




whats wrong with this piece of code:

        if(!model_plugin.empty())
        {
            std::shared_ptr<MotionModel> load = model_factory_->createModelFromPlugin(model_plugin, states_);
            model_ = std::unique_ptr<MotionModel>(load.get());
            std::cout<<"Model Address 1: "<<model_.get()<<"\n";
        }

The problem here is that load is a std::shared_ptr<MotionModel>, and when you call load.get(), you get a raw pointer (MotionModel*) pointing to the object. Then, when you use std::unique_ptr<MotionModel>(load.get()), you create a new std::unique_ptr that thinks it owns the object, but the original std::shared_ptr still owns it. When the std::shared_ptr goes out of scope or is explicitly destroyed, it deletes the object, leaving the std::unique_ptr with a dangling pointer, leading to undefined behavior.

kholase you can not convert shared_ptr to unique ptr but vice versa is possible




what should be the Q: https://stackoverflow.com/questions/36736376/kalman-filter-process-noise-covariance
basically if your real dynamics are not the same as the motion model that you are using the Q is gonna compensate for it by the amount you are lacking! good example is in the above link


uplodaing pic and using it in github: https://stackoverflow.com/questions/52063556/add-image-to-github-readme-md-from-google-drive




c++ and python code at the same pkg:
https://answers.ros.org/question/298740/ros2-c-and-python-in-same-package-is-it-possible/


don't use a folder named scripts in your folder structure because gazebo won't be able to launch
https://github.com/ros-simulation/gazebo_ros_pkgs/issues/1050


namespace Filter{

    Ekf::Ekf()
    {
        std::cout<<"Ctor of Ekf \n";
    }
    
    Ekf::Ekf(std::unique_ptr<MotionModel> motion_model_):
    Fusion(std::move(motion_model_)) 
    {
        std::cout<<"Ctor of Ekf \n";
    }

    void Ekf::setStates(std::shared_ptr<StateSpace> states_)
    {
        this->states_ = states_;
        // RCLCPP_INFO(rclcpp::get_logger("EKF") , "EKF: %i" ,  this->states_->getStates().size() );
    }

    void Ekf::setMotionModel(std::unique_ptr<MotionModel> motion_model_)
    {
        this->motion_model_ = motion_model_ ? std::move(motion_model_) : nullptr;
        // RCLCPP_INFO(rclcpp::get_logger("a") , "address %p" , static_cast<void*>(this));
    }

    void Ekf::setProcessNoise(std::vector<double> Q_)
    {
        int num_states_ = states_->getStates().size();
        int counter_ = 0;
        Q.setZero(num_states_ , num_states_);
        for(int i = 0 ; i <num_states_ ; i++)
        {
            for(int j = 0 ; j<num_states_ ; j++)
            {
                Q(i,j) = Q_.at(counter_);
                counter_++;
            }
        }
        // std::cout<<"Q:" <<Q<<"\n";
    }

    void Ekf::setMeasurementNoise(std::vector<double> R_)
    {
        int num_states_ = states_->getStates().size();
        int counter_ = 0;
        R.setZero(num_states_ , num_states_);
        for(int i = 0 ; i <num_states_ ; i++)
        {
            for(int j = 0 ; j<num_states_ ; j++)
            {
                R(i,j) = R_.at(counter_);
                counter_++;
            }
        }
        // std::cout<<"R:" <<R<<"\n";
    }

    void Ekf::initialize()
    {
        // initialize dimensions of the state space
        if (!this->states_) 
            RCLCPP_ERROR(rclcpp::get_logger("EKF"), "State space pointer is null!");

        int num_states_ = states_->getStates().size(); //[x,y,yaw,x_dot,yaw_dot,x_ddot]
        // int num_inputs_ = 2;
        //for now 2 data is good --> i might have to figure out how to incorporate a_x and a_y data as well which might gives me maybe x and y by double integrating or just use a_x and integrate it once to get x_dot --> the realtion ship is maybe nonlinear and i need to take care of it
        // int num_obs_ = 3; // my imu gives 9 data (3 for orientation - 3 for angular velocity and 3 for accelration in x,y,z direction but im using only yaw data - yaw_dot or angular velocity in z direction)
       
        // Q.setZero(num_states_ , num_states_);
        // // the following number i get from /odom topic of the diff drive controller  which is 6by6 cov matrix for x,y,z,roll,pitch.yaw and in the twist their dots also can be found. i got what ever is related to my state space
        // Q(0,0) = 0.05;
        // Q(1,1) = 0.05;
        // Q(2,2) = 0.05;
        // Q(3,3) = 0.05;
        // Q(4,4) = 0.05;
        // Q(5,5) = 0.05;
        // H = Eigen::MatrixXd(num_obs_ , num_states_);
        // H<< 0,0,1,0,0,0,0,0,0,1; //we extract the yaw dot from imu . lets not use the oienation (yaw) becase i think that data is redudnat and not available directly! but im not sure
        // H<<0,0,1,0,0,0 ,0,0,0,0,1,0 ,0,0,0,0,0,1; //we extract the yaw dot from imu . lets not use the oienation (yaw) becase i think that data is redudnat and not available directly! but im not sure


        // R = Eigen::MatrixXd(num_obs_ , num_obs_);
        // R.setZero(num_obs_ , num_obs_); //for yaw and yaw_rate
        // R.setZero(num_states_ , num_states_);
        // R(0,0) = 4.0e-8;
        // R(1,1) = 4.0e-8;
        // R(2,2) = 4.0e-8;
        // R(3,3) = 4.0e-8;
        // R(4,4) = 4.0e-8;
        // R(5,5) = 10.0e-8;
        // P = Eigen::MatrixXd(num_states_ , num_states_);
        P.setZero(num_states_,num_states_);
        // P.setOnes(num_states_,num_states_);
        // P = P*0.00000001;
        I = Eigen::MatrixXd::Identity(num_states_ , num_states_);

    }

    void Ekf::predict(const rclcpp::Time& current_time_ , const rclcpp::Duration& dt_)
    {
        // RCLCPP_INFO(rclcpp::get_logger("a") , "address %p" , static_cast<void*>(this));
        if(motion_model_)
            A = motion_model_->update(current_time_ , dt_);
        else
            RCLCPP_INFO(rclcpp::get_logger("A") , "asda");
        P = A*P*A.transpose() + Q;
        // std::cout<<"P0: \n"<<P<<"\n";
        // std::cout<<"V_x: "<<states_->getStates()["x_dot"]<<" W: "<<states_->getStates()["yaw_dot"]<<" Yaw:"<< states_->getStates()["yaw"] <<" dt:" <<dt.seconds()<<"\n";
    }

    void Ekf::update(const Observations& observation_)
    {
        autodiff::VectorXreal& X = states_->getStates();
        auto H = observation_.H;
        auto real_measurement_ = observation_.states_;
        // std::cout<<"In the update \n";
        autodiff::MatrixXreal measurement_prediction_ = H*X;
        // std::cout<<H<<"\n \n \n ";
        // std::cout<<X<<"\n \n \n ";
        // std::cout<<measurement_prediction_<<"\n"; //I only get data when i give angular velocity
        // int num_obs_ = 3;
        // autodiff::MatrixXreal imu_measurement_(num_obs_ , 1);

        // tf2::Quaternion quaternion;
        // tf2::fromMsg(imu_source_->getImuData().orientation, quaternion);
            
        //     // Convert quaternion to euler angles directly
        // double roll, pitch, yaw;
        // tf2::Matrix3x3(quaternion).getRPY(roll, pitch, yaw);

        // imu_measurement_<<yaw, imu_source_->getImuData().angular_velocity.z ,imu_source_->getImuData().linear_acceleration.x ;
        // imu_measurement_<<0,0,0;
        autodiff::MatrixXreal measurement_residual_ = real_measurement_ - measurement_prediction_;
        // RCLCPP_INFO_STREAM(rclcpp::get_logger("A") , H);
        // RCLCPP_INFO_STREAM(rclcpp::get_logger("B") , X);
        // std::cout<< imu_measurement_<<"  "<< measurement_prediction_ <<" "<<measurement_residual_<<"\n";
        // std::cout<<imu_source_->getImuData().angular_velocity.z<<"\n";

        
        autodiff::MatrixXreal innovation_covariance_ = H*P*H.transpose() + R;
        // autodiff::MatrixXreal kalman_gain_ = P*H.transpose()*innovation_covariance_.completeOrthogonalDecomposition().pseudoInverse(); //.inverse() doesn't work because we have 0 in the diagonal due to my design choice of having the full states in the H matrix!
        autodiff::MatrixXreal kalman_gain_ = P*H.transpose()*innovation_covariance_.inverse();
 
        // RCLCPP_INFO_STREAM(rclcpp::get_logger("C") , innovation_covariance_);
        // RCLCPP_INFO_STREAM(rclcpp::get_logger("C") , kalman_gain_);
        // std::cout<<"real ---: \n" <<real_measurement_<<"pred --- \n "<< measurement_prediction_ <<"res -- \n "<<measurement_residual_<<"\n";
        // std::cout<<"real ---: \n" <<real_measurement_<<"\n";
        // std::cout<<innovation_covariance_<<"\n";
        // std::cout<<"KALMAN GAIN:\n"<<kalman_gain_<<"\n";
        // std::cout<<"K*res:\n"<<kalman_gain_*measurement_residual_<<"\n";
        // std::cout<<"X_BEFORE: \n" <<X<<"\n";
        X = X + kalman_gain_*measurement_residual_;
        P = (I-kalman_gain_*H)*P*(I-kalman_gain_*H).transpose() + kalman_gain_*R*kalman_gain_.transpose(); // or use P = (I-K*H)*P
        // P = (I-kalman_gain_*H)*P;
        // RCLCPP_INFO_STREAM(rclcpp::get_logger("A") , X);
        // std::cout<<"P: \n"<<P<<"\n --- \n";
        // std::cout<<"X: \n" <<X<<"\n";

    }

    autodiff::VectorXreal Ekf::getStates()
    {
        // const auto index = states_->getStateOrder();
        // Eigen::MatrixXd X(index.size() , 1);
        // for(int i = 0 ; i <index.size() ; i++)
        // {
        //     X(i , 1) = 
        // }
        // for( auto name: index)
        // {
        //     X(index.at(name.first) ,0) = states_->getStates()[name]
        // }
        // X<<states_->getStates()[states_->getStateOrder().at("x")].val(),
        //    states_->getStates()[states_->getStateOrder().at("y")].val(),
        //    states_->getStates()[states_->getStateOrder().at("yaw")].val(),
        //    states_->getStates()[states_->getStateOrder().at("x_dot")].val(),
        //    states_->getStates()[states_->getStateOrder().at("yaw_dot")].val();
        // //    states_->getStates()[states_->getStateOrder().at("x_ddot")].val();
        
        // return X;

        return states_->getStates();
    }



} //namespace Filter




------------------------------
FIlter node backup
// MIT License
//
// Copyright (c) 2023 Soheil Espahbodi Nia
//
// Permission is hereby granted, free of charge, to any person obtaining a copy
// of this software and associated documentation files (the "Software"), to deal
// in the Software without restriction, including without limitation the rights
// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
// copies of the Software, and to permit persons to whom the Software is
// furnished to do so, subject to the following conditions:
//
// The above copyright notice and this permission notice shall be included in all
// copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
// SOFTWARE.

#include<fusion/filter_node.hpp>
// #include<chorno>
using namespace std::chrono_literals;
namespace Filter{
    FilterNode::~FilterNode(){
        if(rviz_marker_.joinable())
            rviz_marker_.join();
    }
    FilterNode::FilterNode(rclcpp::NodeOptions options_):Node("Filter",options_)
    {
        this->declare_parameter<std::vector<std::string>>("states");
        this->declare_parameter<std::vector<double>>("initial_states");
        this->declare_parameter<bool>("use_cmd");
        this->declare_parameter<bool>("publish_tf");
        this->declare_parameter<int>("model_type");
        this->declare_parameter<int>("filter_type");
        this->declare_parameter<double>("rate");
        this->declare_parameter<std::string>("odom_frame");
        this->declare_parameter<std::string>("base_link_frame");
        this->declare_parameter<std::string>("model_plugin");
        // this->declare_parameter<std::vector<double>>("Q_diag");
        this->declare_parameter<std::vector<double>>("Q_full");
        this->declare_parameter<std::vector<double>>("R_full");

        int sensor_id = 0;
        while(true)
        {
            std::vector<std::string> sensor_states;
            std::string sensor_topic;
            std::string msg_type;
            std::string sensor_states_param = "sensor_" + std::to_string(sensor_id) + "_states";
            std::string sensor_topic_param = "sensor_" + std::to_string(sensor_id) + "_topic";
            std::string sensor_msg_type_param = "sensor_" + std::to_string(sensor_id) + "_msg";
            this->declare_parameter<std::string>(sensor_topic_param , std::string()); //default value for params is neccessary essentially when it doesn't exist in the yaml file
            this->declare_parameter<std::string>(sensor_msg_type_param , std::string()); //default value for params is neccessary essentially when it doesn't exist in the yaml file
            this->declare_parameter<std::vector<std::string>>(sensor_states_param , std::vector<std::string>());
            this->get_parameter(sensor_states_param, sensor_states);
            this->get_parameter(sensor_topic_param, sensor_topic);
            this->get_parameter(sensor_msg_type_param, msg_type);
            if (sensor_states.empty() || sensor_topic.empty() || msg_type.empty())
            {
                break; 
            }
            RCLCPP_INFO(this->get_logger() , "Sensor id %i" , sensor_id);
            RCLCPP_INFO(this->get_logger() , "Sensor msg type: %s" , msg_type.c_str());
            RCLCPP_INFO(this->get_logger() , "states: ");
            for (const auto& state : sensor_states) {
                RCLCPP_INFO(this->get_logger() , "--- %s" ,state.c_str() );
            }
            RCLCPP_INFO(this->get_logger() , "topic: %s" ,sensor_topic.c_str() );
            sensor_states_[sensor_topic] = sensor_states;

            //////////////////////
            //create subscription
            if(msg_type == "sensor_msgs::msg::Imu")
            {
                RCLCPP_INFO(this->get_logger() , "IMU SUB");
                auto imu_sub_ = this->create_subscription<sensor_msgs::msg::Imu>(sensor_topic,rclcpp::SensorDataQoS(),[this, sensor_topic](const sensor_msgs::msg::Imu::SharedPtr msg) {
                        imuCallback(msg, sensor_topic);
                    });
                sensor_subs_.push_back(imu_sub_);
            }
            else if (msg_type == "nav_msgs::msg::Odom")
            {
                RCLCPP_INFO(this->get_logger() , "ODOM SUB");
                auto odom_sub_ = this->create_subscription<nav_msgs::msg::Odometry>(sensor_topic, rclcpp::QoS(1) , [this , sensor_topic](const nav_msgs::msg::Odometry::SharedPtr msg){
                    odomCallback(msg , sensor_topic);
                });
                sensor_subs_.push_back(odom_sub_);
            }
            else{
                RCLCPP_INFO(this->get_logger() , "This type is not implemented yet");
            }
            ////////////////
            sensor_id++;
        }

        bool use_cmd;
        this->get_parameter("use_cmd" , use_cmd);
        if(use_cmd)
        {
            auto cmd_vel_sub_ = this->create_subscription<geometry_msgs::msg::Twist>("cmd_vel" , 1 , [this](const geometry_msgs::msg::Twist::SharedPtr msg){
                controlCallback(msg);
            });
            sensor_subs_.push_back(cmd_vel_sub_);
        }



        this->get_parameter("odom_frame" , odom_frame_);
        this->get_parameter("base_link_frame" , base_link_frame_);
        this->get_parameter("publish_tf" , publish_tf_);


        initialize();
        initializeStateAction();

        filtered_odom_pub_ = this->create_publisher<nav_msgs::msg::Odometry>("odom_filtered" , rclcpp::QoS(1));
        yaw_odom_pub_ = this->create_publisher<std_msgs::msg::Float64>("yaw_odom" , rclcpp::QoS(1));
        yaw_filter_pub_ = this->create_publisher<std_msgs::msg::Float64>("yaw_filter" , rclcpp::QoS(1));

        double rate_;
        this->get_parameter("rate" , rate_);
        // timer_ = this->create_wall_timer(std::chrono::nanoseconds(static_cast<long long>((1.0 / rate_) * 1.0e+9)), std::bind(&FilterNode::timerCallback, this));

        const std::chrono::duration<double> timespan{1.0 / rate_};
        timer_ = rclcpp::GenericTimer<rclcpp::VoidCallbackType>::make_shared(
            this->get_clock(), std::chrono::duration_cast<std::chrono::nanoseconds>(timespan),
            std::bind(&FilterNode::timerCallback, this), this->get_node_base_interface()->get_context());
        this->get_node_timers_interface()->add_timer(timer_, nullptr);


        visualization_ = std::make_shared<Visualization::Visualization>();
        params_.visualization_ = visualization_;
        rviz_marker_ = std::thread(&FilterNode::rviz_marker,this ,&params_);


        previous_update_time_ = this->now();

        tf_buffer_ = std::make_shared<tf2_ros::Buffer>(this->get_clock());
        tf_listener_ = std::make_shared<tf2_ros::TransformListener>(*tf_buffer_);
        
        odom_base_link_broadcaster_ = std::make_shared<tf2_ros::TransformBroadcaster>(this);
    }

    void FilterNode::initialize()
    {
        std::vector<std::string> config_states_;
        int model_type;
        int filter_type;
        std::string model_plugin;
        std::vector<double> Q_;
        std::vector<double> R_;
        std::vector<double> initial_states;
        this->get_parameter("states" , config_states_);
        this->get_parameter("model_type" , model_type);
        this->get_parameter("filter_type" , filter_type);
        this->get_parameter("model_plugin" , model_plugin);
        this->get_parameter("Q_full" , Q_);
        this->get_parameter("R_full" , R_);
        this->get_parameter("initial_states" , initial_states);
        for(auto cs : config_states_)
        {
            RCLCPP_INFO(this->get_logger() , "State: %s" , cs.c_str());
        }
        states_ = std::make_shared<StateSpace>(config_states_);
        states_->updateStates(initial_states);
        model_factory_ = std::make_unique<MotionModelFactory>();
        if(!model_plugin.empty())
            model_ = model_factory_->createModelFromPlugin(model_plugin, states_);
        else
            model_ = model_factory_->createModel( static_cast<ModelType>(model_type),  states_);

        local_motion_model_ = model_.get();
        // hub_ = std::make_unique<Filter::MessageHub>(model_.get());
        filter_factory_ = std::make_unique<FilterFactory>();
        filter_ = filter_factory_->createFilter(static_cast<FilterType>(filter_type) , std::move(model_) , states_);
        filter_->setProcessNoise(Q_);
        filter_->setMeasurementNoise(R_);
        filter_->initialize();

    }


    void FilterNode::initializeStateAction()
    {
        imu_state_action_["yaw_dot"] = [](const sensor_msgs::msg::Imu::SharedPtr msg_ ,
                                          Observations& current_obs_,
                                          std::unordered_map<std::string,int> index_)
                                        { current_obs_.states_(index_.at("yaw_dot")) = msg_->angular_velocity.z;};
        imu_state_action_["x_ddot"] = [](const sensor_msgs::msg::Imu::SharedPtr msg_ ,
                                          Observations& current_obs_,
                                          std::unordered_map<std::string,int> index_)
                                        {current_obs_.states_(index_.at("x_ddot")) = msg_->linear_acceleration.x;};
        imu_state_action_["y_ddot"] = [](const sensor_msgs::msg::Imu::SharedPtr msg_ ,
                                          Observations& current_obs_,
                                          std::unordered_map<std::string,int> index_)
                                        {current_obs_.states_(index_.at("y_ddot")) = msg_->linear_acceleration.y;};
        imu_state_action_["z_ddot"] = [](const sensor_msgs::msg::Imu::SharedPtr msg_ ,
                                          Observations& current_obs_,
                                          std::unordered_map<std::string,int> index_)
                                        {current_obs_.states_(index_.at("z_ddot")) = msg_->linear_acceleration.z;};
        imu_state_action_["roll"] = [](const sensor_msgs::msg::Imu::SharedPtr msg_ , Observations& current_obs_,
                                          std::unordered_map<std::string,int> index_)
                                        {
                                            tf2::Quaternion quaternion;
                                            tf2::fromMsg(msg_->orientation, quaternion);
                                            double roll, pitch, yaw;
                                            tf2::Matrix3x3(quaternion).getRPY(roll, pitch, yaw);
                                            current_obs_.states_(index_.at("roll")) = roll;
                                        };
        imu_state_action_["pitch"] = [](const sensor_msgs::msg::Imu::SharedPtr msg_ , Observations& current_obs_,
                                          std::unordered_map<std::string,int> index_)
                                        {
                                            tf2::Quaternion quaternion;
                                            tf2::fromMsg(msg_->orientation, quaternion);
                                            double roll, pitch, yaw;
                                            tf2::Matrix3x3(quaternion).getRPY(roll, pitch, yaw);
                                            current_obs_.states_(index_.at("pitch")) = pitch;
                                        };
        imu_state_action_["yaw"] = [](const sensor_msgs::msg::Imu::SharedPtr msg_ , Observations& current_obs_,
                                          std::unordered_map<std::string,int> index_)
                                        {
                                            tf2::Quaternion quaternion;
                                            tf2::fromMsg(msg_->orientation, quaternion);
                                            double roll, pitch, yaw;
                                            tf2::Matrix3x3(quaternion).getRPY(roll, pitch, yaw);
                                            current_obs_.states_(index_.at("yaw")) = yaw;
                                        };

        odom_state_action_["x"] = [](const nav_msgs::msg::Odometry::SharedPtr msg_, 
                                                               Observations & current_obs_,
                                                               std::unordered_map<std::string, int> index_)
                                    {current_obs_.states_(index_.at("x")) = msg_->pose.pose.position.x ;};
        odom_state_action_["y"] = [](const nav_msgs::msg::Odometry::SharedPtr msg_, 
                                                               Observations & current_obs_,
                                                               std::unordered_map<std::string, int> index_)
                                    {current_obs_.states_(index_.at("y")) = msg_->pose.pose.position.y ;};
        odom_state_action_["z"] = [](const nav_msgs::msg::Odometry::SharedPtr msg_, 
                                                               Observations & current_obs_,
                                                               std::unordered_map<std::string, int> index_)
                                    {current_obs_.states_(index_.at("z")) = msg_->pose.pose.position.z ;};
        odom_state_action_["roll"] = [](const nav_msgs::msg::Odometry::SharedPtr msg_, 
                                                               Observations & current_obs_,
                                                               std::unordered_map<std::string, int> index_)
                                        {
                                            tf2::Quaternion quaternion;
                                            tf2::fromMsg(msg_->pose.pose.orientation, quaternion);
                                            double roll, pitch, yaw;
                                            tf2::Matrix3x3(quaternion).getRPY(roll, pitch, yaw);
                                            current_obs_.states_(index_.at("roll")) = roll;
                                        };
        odom_state_action_["pitch"] = [](const nav_msgs::msg::Odometry::SharedPtr msg_, 
                                                               Observations & current_obs_,
                                                               std::unordered_map<std::string, int> index_)
                                        {       
                                            tf2::Quaternion quaternion;
                                            tf2::fromMsg(msg_->pose.pose.orientation, quaternion);
                                            double roll, pitch, yaw;
                                            tf2::Matrix3x3(quaternion).getRPY(roll, pitch, yaw);
                                            current_obs_.states_(index_.at("pitch")) = pitch;
                                        };
        odom_state_action_["yaw"] = [](const nav_msgs::msg::Odometry::SharedPtr msg_, 
                                                               Observations & current_obs_,
                                                               std::unordered_map<std::string, int> index_)
                                        {
                                            tf2::Quaternion quaternion;
                                            tf2::fromMsg(msg_->pose.pose.orientation, quaternion);
                                            double roll, pitch, yaw;
                                            tf2::Matrix3x3(quaternion).getRPY(roll, pitch, yaw);
                                            current_obs_.states_(index_.at("yaw")) = yaw;
                                        };
        odom_state_action_["x_dot"] = [](const nav_msgs::msg::Odometry::SharedPtr msg_, 
                                                               Observations & current_obs_,
                                                               std::unordered_map<std::string, int> index_)
                                        {current_obs_.states_(index_.at("x_dot")) = msg_->twist.twist.linear.x ;};
        odom_state_action_["y_dot"] = [](const nav_msgs::msg::Odometry::SharedPtr msg_, 
                                                               Observations & current_obs_,
                                                               std::unordered_map<std::string, int> index_)
                                        {current_obs_.states_(index_.at("y_dot")) = msg_->twist.twist.linear.y ;};
        odom_state_action_["z_dot"] = [](const nav_msgs::msg::Odometry::SharedPtr msg_, 
                                                               Observations & current_obs_,
                                                               std::unordered_map<std::string, int> index_)
                                        {current_obs_.states_(index_.at("z_dot")) = msg_->twist.twist.linear.z ;};
        odom_state_action_["roll_dot"] = [](const nav_msgs::msg::Odometry::SharedPtr msg_, 
                                                               Observations & current_obs_,
                                                               std::unordered_map<std::string, int> index_)
                                        {current_obs_.states_(index_.at("roll_dot")) = msg_->twist.twist.angular.x ;};
        odom_state_action_["pitch_dot"] = [](const nav_msgs::msg::Odometry::SharedPtr msg_, 
                                                               Observations & current_obs_,
                                                               std::unordered_map<std::string, int> index_)
                                        {current_obs_.states_(index_.at("pitch_dot")) = msg_->twist.twist.angular.y ;};
        odom_state_action_["yaw_dot"] = [](const nav_msgs::msg::Odometry::SharedPtr msg_, 
                                                               Observations & current_obs_,
                                                               std::unordered_map<std::string, int> index_)
                                        {current_obs_.states_(index_.at("yaw_dot")) = msg_->twist.twist.angular.z ;};
    }

    void FilterNode::imuCallback(const sensor_msgs::msg::Imu::SharedPtr msg_ , std::string topic_name_)
    {
        // RCLCPP_INFO(this->get_logger() , "imu callback: %s" , topic_name_.c_str());

        // tf2::Quaternion quaternion;
        // tf2::fromMsg(msg->orientation, quaternion);
        // double roll, pitch, yaw;
        // tf2::Matrix3x3(quaternion).getRPY(roll, pitch, yaw);
        // RCLCPP_INFO(this->get_logger() , " ----- ");
        // RCLCPP_INFO(this->get_logger() , "state theta 0: %f" , yaw);

        Observations current_obs_;
        autodiff::MatrixXreal H;
        current_obs_.time_ = msg_->header.stamp;
        // RCLCPP_INFO(this->get_logger() , "Time:%f " , current_obs_.time_.seconds()); //rclcpp::Time store the double variable as seconod so no worries about the nano seconds stuff i guess
        auto index_ = states_->getStateOrder();
        // H.setZero(index.size() , index.size());
        H.setZero(states_->states_.size() , states_->states_.size());
        current_obs_.states_.setZero(states_->states_.size());
        // current_obs_.states_.setZero(index.size());
        // RCLCPP_INFO(rclcpp::get_logger("B") , "SIZE: %i" , index.size());
        for (auto sensor_state_ : sensor_states_[topic_name_])
        {
            // RCLCPP_INFO(this->get_logger() ," HERE : %s" , sensor_state_.c_str());
            auto it_ = index_.find(sensor_state_);
            if(imu_state_action_.find(sensor_state_) != imu_state_action_.end())
            {
                imu_state_action_[sensor_state_](msg_ , current_obs_ , index_);
                H(it_->second , it_->second) = 1;
            }
            else{

            }

        }
        // for(int i = 0 ; i <current_obs_.states_.size(); i++)
        // {
        //     RCLCPP_INFO(this->get_logger() , "obs: %f" , current_obs_.states_(i));
        // }
        current_obs_.H = H;
        // RCLCPP_INFO_STREAM(this->get_logger() , H);
        // RCLCPP_INFO_STREAM(this->get_logger() , index.size());
        observations_.push(current_obs_);
        // RCLCPP_INFO(this->get_logger() , "YAW_DOT IN IMU %f" , msg_->angular_velocity.z );

    }

    void FilterNode::odomCallback(const nav_msgs::msg::Odometry::SharedPtr msg_, std::string topic_name_)
    {
        // RCLCPP_INFO(this->get_logger() , "odom callback: %s" , topic_name_.c_str());
        Observations current_obs_;
        autodiff::MatrixXreal H;
        // auto cTime_ = this->now();
        // std::cout<<"Current Time0: "<<cTime_.nanoseconds()<<"\n";
        // std::cout<<"Message Time1: "<<msg_->header.stamp.sec<<" -- "<<msg_->header.stamp.nanosec<<"\n";
        // rclcpp::Duration time_diff_ = cTime_ - msg_->header.stamp;
        // std::cout<<"Time difference : "<< time_diff_.seconds()<<"\n";
        current_obs_.time_ = msg_->header.stamp;
        auto index_ = states_->getStateOrder();
        H.setZero(states_->states_.size(), states_->states_.size());
        current_obs_.states_.setZero(states_->states_.size());
        for (auto sensor_state_ : sensor_states_[topic_name_])
        {
            auto it = index_.find(sensor_state_);
            if(odom_state_action_.find(sensor_state_) != odom_state_action_.end())
            {
                odom_state_action_.at(sensor_state_)(msg_ ,current_obs_ , index_ );
                H(it->second , it->second) = 1;
            }
            else
            {

            }

        }
        // for(int i = 0 ; i <current_obs_.states_.size(); i++)
        // {
        //     RCLCPP_INFO(this->get_logger() , "obs: %f" , current_obs_.states_(i));
        // }
        current_obs_.H = H;
        // RCLCPP_INFO_STREAM(this->get_logger() , H);
        // RCLCPP_INFO_STREAM(this->get_logger() , index.size());
        observations_.push(current_obs_);
            
        // ///////publishing yaw data from odom in a topic//////////
        tf2::Quaternion quaternion_;
        tf2::fromMsg(msg_->pose.pose.orientation, quaternion_);
        double roll_, pitch_, yaw_;
        tf2::Matrix3x3(quaternion_).getRPY(roll_, pitch_, yaw_);
        std_msgs::msg::Float64 d_;
        d_.data = yaw_;
        // RCLCPP_INFO_STREAM(this->get_logger() , yaw_);
        yaw_odom_pub_->publish(d_);

        // RCLCPP_INFO(this->get_logger() , "YAW IN ODOM %f" ,yaw_ );
        // RCLCPP_INFO(this->get_logger() , "YAW_DOT IN ODOM %f" , msg_->twist.twist.angular.z );


        ///////////////////////////////
        // if (observations_.empty())
        // {
        //     RCLCPP_INFO(this->get_logger(), "No obs is in queue %i", observations_.size());
        // }

        // geometry_msgs::msg::Pose2D pose_;
        // while(!observations_.empty())
        // {
        //     // if(observations_.top().time_ > this->now())
        //     //     break;
        //     rclcpp::Time cur =msg->header.stamp;
        //     rclcpp::Duration dt_ = cur - previous_update_time_;
        //     filter_->predict(cTime_ , dt_);
        //     filter_->update(observations_.top());
        //     // RCLCPP_INFO(this->get_logger() , "some obs is in queue %i" , observations_.size());
        //     previous_update_time_ = cur;
        //     RCLCPP_INFO(this->get_logger() , "dt: %f" , dt_.seconds());
        //     observations_.pop();
        // }

        // autodiff::VectorXreal states_ = filter_->getStates();
        // std_msgs::msg::Float64 dd;
        // dd.data = states_(2).val();
        // yaw_filter_pub_->publish(dd);
    }


    // void FilterNode::imuCallback(const sensor_msgs::msg::Imu::SharedPtr msg , std::string topic_name_)
    // {
    //     // RCLCPP_INFO(this->get_logger() , "imu callback: %s" , topic_name_.c_str());

    //     // tf2::Quaternion quaternion;
    //     // tf2::fromMsg(msg->orientation, quaternion);
    //     // double roll, pitch, yaw;
    //     // tf2::Matrix3x3(quaternion).getRPY(roll, pitch, yaw);
    //     // RCLCPP_INFO(this->get_logger() , " ----- ");
    //     // RCLCPP_INFO(this->get_logger() , "state theta 0: %f" , yaw);

    //     Observations current_obs_;
    //     autodiff::MatrixXreal H;
    //     current_obs_.time_ = msg->header.stamp;
    //     // RCLCPP_INFO(this->get_logger() , "Time:%f " , current_obs_.time_.seconds()); //rclcpp::Time store the double variable as seconod so no worries about the nano seconds stuff i guess
    //     auto index = states_->getStateOrder();
    //     // H.setZero(index.size() , index.size());
    //     H.setZero(states_->states_.size() , states_->states_.size());
    //     current_obs_.states_.setZero(states_->states_.size());
    //     // current_obs_.states_.setZero(index.size());
    //     // RCLCPP_INFO(rclcpp::get_logger("B") , "SIZE: %i" , index.size());
    //     for (auto sensor_state_ : sensor_states_[topic_name_])
    //     {
    //         auto it = index.find(sensor_state_);
    //         if (sensor_state_ == "yaw_dot")
    //         {
    //             current_obs_.states_(it->second) = msg->angular_velocity.z;
    //             RCLCPP_INFO(this->get_logger() , "yaw dot: %f" , current_obs_.states_(it->second));
    //         }
    //         else if (sensor_state_ == "x_ddot")
    //         {
    //             current_obs_.states_(it->second) = msg->linear_acceleration.x;
    //         }
    //         else if ( sensor_state_ =="roll" || sensor_state_ =="pitch" || sensor_state_ == "yaw" ){
    //             tf2::Quaternion quaternion;
    //             tf2::fromMsg(msg->orientation, quaternion);
    //             double roll, pitch, yaw;
    //             tf2::Matrix3x3(quaternion).getRPY(roll, pitch, yaw);
    //             if(sensor_state_ =="roll")
    //                 current_obs_.states_(it->second) = roll;
    //             else if(sensor_state_ =="pitch")
    //                 current_obs_.states_(it->second) = pitch;
    //             else if(sensor_state_ =="yaw")
    //                 current_obs_.states_(it->second) = yaw;
    //         }
    //         else{

    //         }

    //         H(it->second , it->second) = 1;
    //     }
    //     // for(int i = 0 ; i <current_obs_.states_.size(); i++)
    //     // {
    //     //     RCLCPP_INFO(this->get_logger() , "obs: %f" , current_obs_.states_(i));
    //     // }
    //     current_obs_.H = H;
    //     // RCLCPP_INFO_STREAM(this->get_logger() , H);
    //     // RCLCPP_INFO_STREAM(this->get_logger() , index.size());
    //     observations_.push(current_obs_);
    //     RCLCPP_INFO(this->get_logger() , "YAW_DOT IN IMU %f" , msg->angular_velocity.z );

    // }

    // void FilterNode::odomCallback(const nav_msgs::msg::Odometry::SharedPtr msg, std::string topic_name_)
    // {
    //     // RCLCPP_INFO(this->get_logger() , "odom callback: %s" , topic_name_.c_str());
    //     Observations current_obs_;
    //     autodiff::MatrixXreal H;
    //     auto cTime_ = this->now();
    //     std::cout<<"Current Time0: "<<cTime_.nanoseconds()<<"\n";
    //     std::cout<<"Message Time1: "<<msg->header.stamp.sec<<" -- "<<msg->header.stamp.nanosec<<"\n";
    //     rclcpp::Duration time_diff_ = cTime_ - msg->header.stamp;
    //     std::cout<<"Time difference : "<< time_diff_.seconds()<<"\n";
    //     current_obs_.time_ = msg->header.stamp;
    //     auto index = states_->getStateOrder();
    //     H.setZero(states_->states_.size(), states_->states_.size());
    //     current_obs_.states_.setZero(states_->states_.size());
    //     for (auto sensor_state_ : sensor_states_[topic_name_])
    //     {
    //         auto it = index.find(sensor_state_);
    //         if (sensor_state_ == "x")
    //         {
    //             current_obs_.states_(it->second) = msg->pose.pose.position.x;
    //         }
    //         else if (sensor_state_ == "y")
    //         {
    //             current_obs_.states_(it->second) = msg->pose.pose.position.y;
    //         }
    //         else if (sensor_state_ == "z")
    //         {
    //             current_obs_.states_(it->second) = msg->pose.pose.position.z;
    //         }
    //         else if (sensor_state_ == "roll" || sensor_state_ == "pitch" || sensor_state_ == "yaw")
    //         {
    //             tf2::Quaternion quaternion;
    //             tf2::fromMsg(msg->pose.pose.orientation, quaternion);
    //             double roll, pitch, yaw;
    //             tf2::Matrix3x3(quaternion).getRPY(roll, pitch, yaw);
    //             if (sensor_state_ == "roll")
    //                 current_obs_.states_(it->second) = roll;
    //             else if (sensor_state_ == "pitch")
    //                 current_obs_.states_(it->second) = pitch;
    //             else if (sensor_state_ == "yaw")
    //                 current_obs_.states_(it->second) = yaw;
    //         }
    //         else if (sensor_state_ == "x_dot")
    //         {
    //             current_obs_.states_(it->second) = msg->twist.twist.linear.x;
    //         }
    //         else if (sensor_state_ == "y_dot")
    //         {
    //             current_obs_.states_(it->second) = msg->twist.twist.linear.y;
    //         }
    //         else if (sensor_state_ == "z_dot")
    //         {
    //             current_obs_.states_(it->second) = msg->twist.twist.linear.z;
    //         }
    //         else if (sensor_state_ == "roll_dot")
    //         {
    //             current_obs_.states_(it->second) = msg->twist.twist.angular.x;
    //         }
    //         else if (sensor_state_ == "pitch_dot")
    //         {
    //             current_obs_.states_(it->second) = msg->twist.twist.angular.y;
    //         }
    //         else if (sensor_state_ == "yaw_dot")
    //         {
    //             current_obs_.states_(it->second) = msg->twist.twist.angular.z;
    //         }
    //         else
    //         {
    //         }

    //         H(it->second , it->second) = 1;
    //     }
    //     // for(int i = 0 ; i <current_obs_.states_.size(); i++)
    //     // {
    //     //     RCLCPP_INFO(this->get_logger() , "obs: %f" , current_obs_.states_(i));
    //     // }
    //     current_obs_.H = H;
    //     // RCLCPP_INFO_STREAM(this->get_logger() , H);
    //     // RCLCPP_INFO_STREAM(this->get_logger() , index.size());
    //     observations_.push(current_obs_);
            
    //     // ///////publishing yaw data from odom in a topic//////////
    //     tf2::Quaternion quaternion;
    //     tf2::fromMsg(msg->pose.pose.orientation, quaternion);
    //     double roll, pitch, yaw;
    //     tf2::Matrix3x3(quaternion).getRPY(roll, pitch, yaw);
    //     std_msgs::msg::Float64 d;
    //     d.data = yaw;
    //     RCLCPP_INFO_STREAM(this->get_logger() , yaw);
    //     yaw_odom_pub_->publish(d);

    //     RCLCPP_INFO(this->get_logger() , "YAW IN ODOM %f" ,yaw );
    //     RCLCPP_INFO(this->get_logger() , "YAW_DOT IN ODOM %f" , msg->twist.twist.angular.z );


    //     ///////////////////////////////
    //     // if (observations_.empty())
    //     // {
    //     //     RCLCPP_INFO(this->get_logger(), "No obs is in queue %i", observations_.size());
    //     // }

    //     // geometry_msgs::msg::Pose2D pose_;
    //     // while(!observations_.empty())
    //     // {
    //     //     // if(observations_.top().time_ > this->now())
    //     //     //     break;
    //     //     rclcpp::Time cur =msg->header.stamp;
    //     //     rclcpp::Duration dt_ = cur - previous_update_time_;
    //     //     filter_->predict(cTime_ , dt_);
    //     //     filter_->update(observations_.top());
    //     //     // RCLCPP_INFO(this->get_logger() , "some obs is in queue %i" , observations_.size());
    //     //     previous_update_time_ = cur;
    //     //     RCLCPP_INFO(this->get_logger() , "dt: %f" , dt_.seconds());
    //     //     observations_.pop();
    //     // }

    //     // autodiff::VectorXreal states_ = filter_->getStates();
    //     // std_msgs::msg::Float64 dd;
    //     // dd.data = states_(2).val();
    //     // yaw_filter_pub_->publish(dd);
    // }

    void FilterNode::controlCallback(const geometry_msgs::msg::Twist::SharedPtr msg)
    {
        // RCLCPP_INFO(this->get_logger() , "CmdVel callback");
        if(local_motion_model_)
            local_motion_model_->setVelAndAngVelFromTwist(*msg);
        
    }

    void FilterNode::timerCallback()
    {
        static rclcpp::Time pre_time_ =  rclcpp::Clock().now();
        rclcpp::Time cur_time_ = rclcpp::Clock().now();
        // RCLCPP_INFO(this->get_logger() , "TIME0: %f" , this->now().seconds()); // Nodes time which depends on use_sim_time variable
        // RCLCPP_INFO(this->get_logger() , "TIME1: %f" , rclcpp::Clock().now().seconds()); //Real time - Unix time
        if(observations_.empty())
        {
            RCLCPP_INFO(this->get_logger() , "No obs is in queue %i" , observations_.size());
            // auto cur_time_ = this->now();
            // auto dt_ = cur_time_ - previous_update_time_;
            // filter_->predict(cur_time_,dt_ );
            // previous_update_time_ = cur_time_;
        }
        params_.time_ = this->now();
        geometry_msgs::msg::Pose2D pose_;
        while (!observations_.empty())
        {
            // if(observations_.top().time_ > this->now())
            //     break;
            rclcpp::Time cur_obs_time_ = observations_.top().time_;
            auto dt_ = cur_obs_time_ - previous_update_time_;
            filter_->predict(cur_obs_time_, dt_);
            filter_->update(observations_.top());
            // RCLCPP_INFO(this->get_logger() , "some obs is in queue %i" , observations_.size());
            previous_update_time_ = cur_obs_time_;
            // RCLCPP_INFO(this->get_logger(), "dt: %f", dt_.seconds());
            observations_.pop();
            ///////lookup transform for now its for debugging purpose////////////////////
            // try
            // {
            //     geometry_msgs::msg::TransformStamped transform = tf_buffer_->lookupTransform(
            //         "odom", "base_link", tf2::TimePointZero);

            //     // RCLCPP_INFO(this->get_logger(), "Base link pose in odom frame: %f %f %f",
            //     //             transform.transform.translation.x,
            //     //             transform.transform.translation.y,
            //     //             transform.transform.translation.z);
            //     double roll, pitch, yaw;
            //     tf2::Quaternion quat;
            //     tf2::fromMsg(transform.transform.rotation, quat);
            //     tf2::Matrix3x3(quat).getRPY(roll, pitch, yaw);

            //     RCLCPP_INFO(this->get_logger(), "Yaw angle of base_link w.r.t. odom: %f", yaw);
            // }
            // catch (tf2::TransformException &ex)
            // {
            //     RCLCPP_ERROR(this->get_logger(), "Transform lookup failed: %s", ex.what());
            // }
        }

        ///////////////////publishing filtered data into a topic///////////// 
        autodiff::VectorXreal sta_ = filter_->getStates();
        filtered_odom_.header.frame_id = odom_frame_;
        filtered_odom_.child_frame_id = base_link_frame_;
        filtered_odom_.header.stamp = this->now();
        filtered_odom_.pose.pose.position.x = sta_(0).val();
        filtered_odom_.pose.pose.position.y = sta_(1).val();


        tf2::Quaternion quaternion_;
        quaternion_.setRPY(0.0,0.0,sta_(2).val());
        // int maxIndex = 0;
        // for (int i = 1; i < 4; ++i) {
        //     if (std::fabs(quaternion_[i]) > std::fabs(quaternion_[maxIndex])) {
        //         maxIndex = i;
        //     }
        // }

        //     RCLCPP_INFO(this->get_logger() , "MAX INDEX %i" , maxIndex);
        // https://stackoverflow.com/questions/72219304/eliminating-sign-flips-in-quaternion-data-from-sensors
        // if (quaternion_[maxIndex] < 0.0) {
        //     quaternion_[maxIndex] = -quaternion_[maxIndex];
        // }


        geometry_msgs::msg::Quaternion orientation_msg_;
        tf2::convert(quaternion_ , orientation_msg_);
        filtered_odom_.pose.pose.orientation = orientation_msg_;
        filtered_odom_pub_->publish(filtered_odom_);
        // /////////////////////publishing yaw in a topic//////////////////
        autodiff::VectorXreal st_ = filter_->getStates();
        std_msgs::msg::Float64 d;
        d.data = st_(2).val();
        yaw_filter_pub_->publish(d);

        // ////////////////////visualization//////////////////
        // autodiff::VectorXreal states_ = filter_->getStates();

        // pose_.x = states_(0).val();
        // pose_.y = states_(1).val();
        // pose_.theta = states_(2).val();
        // // RCLCPP_INFO(this->get_logger() , "x,y,theta: %f , %f, %f" , pose_.x , pose_.y , pose_.theta);
        // RCLCPP_INFO(this->get_logger() , "state theta 1: %f" , pose_.theta);
        // visualization_->addArrow(pose_);
        // visualization_->publishArrow();
        // visualization_->initialize();


        // RCLCPP_INFO_STREAM(rclcpp::get_logger("rate logger") , 1/(cur_time_-pre_time_).seconds()); // *
        pre_time_ = cur_time_;

        ///////////////Send filtered states tf//////////////////////
        if(publish_tf_)
        {
            autodiff::VectorXreal s_ = filter_->getStates();
            tf2::Quaternion quat;
            auto index = states_->getStateOrder();
            quat.setRPY(index.count("roll")  ? s_(index.at("roll")).val()  : 0 ,
                        index.count("pitch") ? s_(index.at("pitch")).val() : 0 ,
                        index.count("yaw")   ? s_(index.at("yaw")).val()   : 0 );
            odom_base_link_transform_.header.frame_id = odom_frame_;
            odom_base_link_transform_.child_frame_id = base_link_frame_;
            rclcpp::Duration duration(0, 10000000000); //10000 ms
            odom_base_link_transform_.header.stamp = this->now();// - duration;
            odom_base_link_transform_.transform.translation.x = index.count("x") ? s_(index.at("x")).val() : 0;
            odom_base_link_transform_.transform.translation.y = index.count("y") ? s_(index.at("y")).val() : 0;
            odom_base_link_transform_.transform.translation.z = index.count("z") ? s_(index.at("z")).val() : 0;
            odom_base_link_transform_.transform.rotation.x = quat.getX();  
            odom_base_link_transform_.transform.rotation.y = quat.getY();  
            odom_base_link_transform_.transform.rotation.z = quat.getZ();  
            odom_base_link_transform_.transform.rotation.w = quat.getW();  
            odom_base_link_broadcaster_->sendTransform(odom_base_link_transform_);
        }
    }
    std::shared_ptr<StateSpace> FilterNode::getStateSpace()
    {
        return std::move(states_);
    }
} // namespace Filter


-------------------------------
motion mdoel baackup


// MIT License
//
// Copyright (c) 2023 Soheil Espahbodi Nia
//
// Permission is hereby granted, free of charge, to any person obtaining a copy
// of this software and associated documentation files (the "Software"), to deal
// in the Software without restriction, including without limitation the rights
// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
// copies of the Software, and to permit persons to whom the Software is
// furnished to do so, subject to the following conditions:
//
// The above copyright notice and this permission notice shall be included in all
// copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
// SOFTWARE.

#include "fusion/motion_model.hpp"
namespace Filter{
    MotionModel::MotionModel(): position_{0.0,0.0,0.0} ,angle_{0.0,0.0,0.0} , velocity_{0.0,0.0,0.0}, angular_velocity_{0.0,0.0,0.0}, dt_(rclcpp::Duration::from_seconds(0))
    {
        std::cout<<"Ctor of MotionModel \n";
        
    }

    MotionModel::~MotionModel(){}

    autodiff::MatrixXreal MotionModel::update(const rclcpp::Time& current_time_ , const rclcpp::Duration& dt)
    {
        static rclcpp::Time previous_time_ = current_time_;
        // dt_ = current_time_ - previous_time_;
        dt_ = dt;
        autodiff::VectorXreal& state_ = states_->getStates();
        autodiff::VectorXreal newState; 
        
        //////Test///////////        
        // std::cout<<"states Jacobian Test:\n "<<this->getJacobian()<<"\n \n";
        // std::cout<<"States: \n"<<state_<<"\n \n";
        ////////////////////
        autodiff::MatrixXreal J = jacobian( [&](auto state_){
            return this->propagate(state_); 
            }, wrt(state_), at(state_), newState);
        // std::cout<<"states Jacobian:\n "<<J<<"\n \n";
        // std::cout<<"dt:\n "<<dt_.seconds()<<"\n \n";
        // std::cout<<"prev:\n "<<previous_time_.seconds()<<"\n \n";
        // std::cout<<"curr:\n "<<current_time_.seconds()<<"\n \n";
        // std::cout<<"prev nano:\n "<<previous_time_.nanoseconds()<<"\n \n";
        // std::cout<<"curr nano:\n "<<current_time_.nanoseconds()<<"\n \n";
        previous_time_ = current_time_;
        
        for(int i = 0 ; i<state_.size() ; i++)
            state_(i) = newState(i).val();
        normalizeAngle(states_->getStates()[states_->getStateOrder().at("yaw")].val());
        // RCLCPP_INFO_STREAM(rclcpp::get_logger("STATE") , state_);

        return J;  //retrun nazari seg fault mide!!!!
    }

    void MotionModel::setStates(std::shared_ptr<StateSpace> states_)
    {
        this->states_ = states_;
    }

    void MotionModel::setVelAndAngVelFromTwist(const geometry_msgs::msg::Twist& twist_)
    {
        if(twist_.linear.x == 0)
            states_->getStates()[states_->getStateOrder().at("x_dot")] = twist_.linear.x;
        // states_->getStates()[states_->getStateOrder().at("yaw_dot")] = twist_.angular.z;
    }
    void MotionModel::normalizeAngle(double& angle_)
    {
        while(angle_>M_PI)
            angle_ -= 2.0*M_PI;
        while(angle_<-M_PI)
            angle_ += 2.0*M_PI;
    }
} //namespace Filter